{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # 机器学习练习 5 Scikit-learn的介绍\n",
    "\n",
    "整理编译：黄海广 haiguang2000@wzu.edu.cn,光城"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在本节教程中将会绘制几个图形，于是我们激活matplotlib,使得在notebook中显示内联图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 为什么要出这个教程？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scikit-learn` 提供最先进的机器学习算法。 但是，这些算法不能直接用于原始数据。 原始数据需要事先进行预处理。 因此，除了机器学习算法之外，scikit-learn还提供了一套预处理方法。此外，`scikit-learn` 提供用于流水线化这些估计器的连接器(即转换器，回归器，分类器，聚类器等)。\n",
    "\n",
    "在本教程中,将介绍`scikit-learn` 函数集，允许流水线估计器、评估这些流水线、使用超参数优化调整这些流水线以及创建复杂的预处理步骤。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.基本用例：训练和测试分类器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于第一个示例，我们将在数据集上训练和测试一个分类器。 我们将使用此示例来回忆`scikit-learn`的API。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们将使用`digits`数据集，这是一个手写数字的数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "#returns (data, target)\n",
    "X, y = load_digits(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "digits = load_digits()\n",
    "plt.gray() #doctest: +SKIP\n",
    "plt.imshow(digits.images[9]) #doctest: +SKIP\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`X`中的每行包含64个图像像素的强度。 对于`X`中的每个样本，我们得到表示所写数字对应的`y`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The digit in the image is 0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAEF0lEQVR4nO3dv2oeZBiH4TcSIVksCjqo4FDQpQYK2QT/IYLg4uAkCB6CIA4uLm4KnoDQwVOoUCddHARbl4CCiKCQoVWhOiTQwucJpBmf3H5c15hv+H0Qbl7IkGdns9ksoOehi/4CwNnECVHihChxQpQ4IWr3vA9P76+t/FPu9aPj0b13P7kxtvXKa1fGtq69c3Vs65H9h8e2pu3trp2zfu7lhChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQtS55xi21eR5hLXW2vx6a2zrr8PLY1vPvPj+2NaX1z4a21prrTevPDm6dxYvJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6Iy5xh+Pv53bGvyPMJaax19/enY1lOP7Y9tHfx9Mrb11U9/jm2t5RwDcA5xQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4ISpzK+Xuyb2xrUuHL49trTV7v2TSC1cv/p7INvNyQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4ISpzjuHOyenY1huvPju2tc1u3537nT1xaW9sq8LLCVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihKjMOYbH9+f+3f53Px6Pba211nr7YGzqn5N7Y1s3b/4+tvXeW8+PbVV4OSFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBCVOcfw9KP7Y1t//HBrbGutta4fzZ1j+OzGL2Nbkz5+/bmL/grjvJwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidE7Ww2mwd+eHp/PfjD/7Evvv9tdO/Dz78Z2zo4vDy29e0HL41tbbO93bVz1s+9nBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTog69xwDcHG8nBAlTogSJ0SJE6LECVHihKj/APCQTb58v7biAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[0].reshape(8, 8), cmap='Blues');# 下面完成灰度图的绘制\n",
    "# 灰度显示图像\n",
    "plt.axis('off')# 关闭坐标轴\n",
    "\n",
    "print('The digit in the image is {}'.format(y[0]))# 格式化打印"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在机器学习中，我们应该通过在不同的数据集上进行训练和测试来评估我们的模型。`train_test_split` 是一个用于将数据拆分为两个独立数据集的效用函数。`stratify`参数可强制将训练和测试数据集的类分布与整个数据集的类分布相同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, ..., 8, 9, 8])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.25, random_state=42)\n",
    "\n",
    "# 划分数据为训练集与测试集,添加stratify参数，以使得训练和测试数据集的类分布与整个数据集的类分布相同。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一旦我们拥有独立的培训和测试集，我们就可以使用`fit`方法学习机器学习模型。 我们将使用`score`方法来测试此方法，依赖于默认的准确度指标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the LogisticRegression is 0.9622\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression  # 求出Logistic回归的精确度得分\n",
    "\n",
    "clf = LogisticRegression(\n",
    "    solver='lbfgs', multi_class='ovr', max_iter=5000, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print('Accuracy score of the {} is {:.4f}'.format(clf.__class__.__name__,\n",
    "                                                  accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ?clf.score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scikit-learn`的API在分类器中是一致的。因此，我们可以通过`RandomForestClassifier`轻松替换`LogisticRegression`分类器。这些更改很小，仅与分类器实例的创建有关。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the RandomForestClassifier is 0.97\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# RandomForestClassifier轻松替换LogisticRegression分类器\n",
    "clf = RandomForestClassifier(n_estimators=1000, n_jobs=-1, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print('Accuracy score of the {} is {:.2f}'.format(clf.__class__.__name__, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the XGBClassifier is 0.96\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "clf = XGBClassifier(n_estimators=1000,eval_metric='mlogloss',use_label_encoder=False)\n",
    "clf.fit(X_train, y_train)\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print('Accuracy score of the {} is {:.2f}'.format(clf.__class__.__name__, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the GradientBoostingClassifier is 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clf = GradientBoostingClassifier(n_estimators=100, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print('Accuracy score of the {} is {:.2f}'.format(clf.__class__.__name__,\n",
    "                                                  accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the GradientBoostingClassifier is 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = balanced_accuracy_score(y_pred, y_test)\n",
    "print('Accuracy score of the {} is {:.2f}'.format(clf.__class__.__name__,\n",
    "                                                  accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the SVC is 0.99\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "clf = SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print('Accuracy score of the {} is {:.2f}'.format(clf.__class__.__name__,\n",
    "                                                  accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the LinearSVC is 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\miniconda\\envs\\DL\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    }
   ],
   "source": [
    "clf = LinearSVC()\n",
    "clf.fit(X_train, y_train)\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print('Accuracy score of the {} is {:.2f}'.format(clf.__class__.__name__,\n",
    "                                                  accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 标准化您的数据\n",
    "在学习模型之前可能需要预处理。例如，一个用户可能对创建手工制作的特征或者算法感兴趣，那么他可能会对数据进行一些先验假设。\n",
    "\n",
    "在我们的例子中，线性模型使用的求解器期望数据被规范化。因此，我们需要在训练模型之前标准化数据。为了观察这个必要条件，我们将检查训练模型所需的迭代次数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`MinMaxScaler`变换器用于归一化数据，`StandardScaler`用于标准化数据。该标量应该以下列方式应用：学习（即，`fit`方法）训练集上的统计数据并标准化（即，`transform`方法）训练集和测试集。 最后，我们将训练和测试这个模型并得到归一化后的数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "#fit_transform,transform的区别是前者包含了fit，即先求出数据的均值、方差等属性值\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the LinearSVC is 0.97\n"
     ]
    }
   ],
   "source": [
    "clf = LinearSVC()\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "accuracy = clf.score(X_test_scaled, y_test)\n",
    "print('Accuracy score of the {} is {:.2f}'.format(clf.__class__.__name__,\n",
    "                                                  accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the LinearSVC is 0.95\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "#svm的LinearSVC的参数max_iter默认值为1000，改为更大的值，这里将其改为10000\n",
    "clf = LinearSVC(max_iter=10000)\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "accuracy = clf.score(X_test_scaled, y_test)\n",
    "print('Accuracy score of the {} is {:.2f}'.format(clf.__class__.__name__,\n",
    "                                                  accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[45  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 41  0  0  0  0  1  0  2  0]\n",
      " [ 0  0 44  0  0  0  0  0  0  0]\n",
      " [ 0  1  0 44  0  0  0  0  0  0]\n",
      " [ 0  1  0  0 45  0  0  1  0  1]\n",
      " [ 0  0  0  1  0 44  0  0  1  1]\n",
      " [ 0  1  0  0  0  0 43  0  2  0]\n",
      " [ 0  0  0  1  0  0  0 44  0  2]\n",
      " [ 0  2  0  0  0  0  1  0 38  1]\n",
      " [ 0  0  0  0  0  2  0  0  0 40]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1   2   3   4   5   6   7   8   9\n",
       "0  45   0   0   0   0   0   0   0   0   0\n",
       "1   0  41   0   0   0   0   1   0   2   0\n",
       "2   0   0  44   0   0   0   0   0   0   0\n",
       "3   0   1   0  44   0   0   0   0   0   0\n",
       "4   0   1   0   0  45   0   0   1   0   1\n",
       "5   0   0   0   1   0  44   0   0   1   1\n",
       "6   0   1   0   0   0   0  43   0   2   0\n",
       "7   0   0   0   1   0   0   0  44   0   2\n",
       "8   0   2   0   0   0   0   1   0  38   1\n",
       "9   0   0   0   0   0   2   0   0   0  40"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    (confusion_matrix(y_pred, y_test)),\n",
    "    columns=range(10),\n",
    "    index=range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        45\n",
      "           1       0.89      0.93      0.91        44\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       0.96      0.98      0.97        45\n",
      "           4       1.00      0.94      0.97        48\n",
      "           5       0.96      0.94      0.95        47\n",
      "           6       0.96      0.93      0.95        46\n",
      "           7       0.98      0.94      0.96        47\n",
      "           8       0.88      0.90      0.89        42\n",
      "           9       0.89      0.95      0.92        42\n",
      "\n",
      "    accuracy                           0.95       450\n",
      "   macro avg       0.95      0.95      0.95       450\n",
      "weighted avg       0.95      0.95      0.95       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 交叉验证\n",
    "\n",
    "分割数据对于评估统计模型性能是必要的。 但是，它减少了可用于学习模型的样本数量。 因此，应尽可能使用交叉验证。有多个拆分也会提供有关模型稳定性的信息。\n",
    "\n",
    "`scikit-learn`提供了三个函数：`cross_val_score`，`cross_val_predict`和`cross_validate`。 后者提供了有关拟合时间，训练和测试分数的更多信息。 我也可以一次返回多个分数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "clf = LogisticRegression(\n",
    "    solver='lbfgs', multi_class='auto', max_iter=1000, random_state=42)\n",
    "scores = cross_validate(\n",
    "    clf, X_train_scaled, y_train, cv=3, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'l1_ratio': None,\n",
       " 'max_iter': 1000,\n",
       " 'multi_class': 'auto',\n",
       " 'n_jobs': None,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': 42,\n",
       " 'solver': 'lbfgs',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.075209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.975501</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.065725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.957684</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.087020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.962138</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score  train_score\n",
       "0  0.075209         0.0    0.975501          1.0\n",
       "1  0.065725         0.0    0.957684          1.0\n",
       "2  0.087020         0.0    0.962138          1.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_scores = pd.DataFrame(scores)\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 网格搜索调参\n",
    "可以通过穷举搜索来优化超参数。`GridSearchCV`提供此类实用程序，并通过参数网格进行交叉验证的网格搜索。\n",
    "\n",
    "如下例子，我们希望优化`LogisticRegression`分类器的`C`和`penalty`参数。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=LogisticRegression(max_iter=5000, random_state=42,\n",
       "                                          solver='saga'),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'C': [0.01, 0.1, 1, 10], 'penalty': ['l2', 'l1']}],\n",
       "             return_train_score=True)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf = LogisticRegression(\n",
    "    solver='saga', multi_class='auto', random_state=42, max_iter=5000)\n",
    "param_grid = {\n",
    "    'logisticregression__C': [0.01, 0.1, 1],\n",
    "    'logisticregression__penalty': ['l2', 'l1']\n",
    "}\n",
    "tuned_parameters = [{\n",
    "    'C': [0.01, 0.1, 1, 10],\n",
    "    'penalty': ['l2', 'l1'],\n",
    "}]\n",
    "grid = GridSearchCV(\n",
    "    clf, tuned_parameters, cv=3, n_jobs=-1, return_train_score=True)\n",
    "grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以使用`get_params()`检查管道的所有参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv': 3,\n",
       " 'error_score': nan,\n",
       " 'estimator__C': 1.0,\n",
       " 'estimator__class_weight': None,\n",
       " 'estimator__dual': False,\n",
       " 'estimator__fit_intercept': True,\n",
       " 'estimator__intercept_scaling': 1,\n",
       " 'estimator__l1_ratio': None,\n",
       " 'estimator__max_iter': 5000,\n",
       " 'estimator__multi_class': 'auto',\n",
       " 'estimator__n_jobs': None,\n",
       " 'estimator__penalty': 'l2',\n",
       " 'estimator__random_state': 42,\n",
       " 'estimator__solver': 'saga',\n",
       " 'estimator__tol': 0.0001,\n",
       " 'estimator__verbose': 0,\n",
       " 'estimator__warm_start': False,\n",
       " 'estimator': LogisticRegression(max_iter=5000, random_state=42, solver='saga'),\n",
       " 'n_jobs': -1,\n",
       " 'param_grid': [{'C': [0.01, 0.1, 1, 10], 'penalty': ['l2', 'l1']}],\n",
       " 'pre_dispatch': '2*n_jobs',\n",
       " 'refit': True,\n",
       " 'return_train_score': True,\n",
       " 'scoring': None,\n",
       " 'verbose': 0}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.514647</td>\n",
       "      <td>0.031017</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.01, 'penalty': 'l2'}</td>\n",
       "      <td>0.953229</td>\n",
       "      <td>0.930958</td>\n",
       "      <td>0.935412</td>\n",
       "      <td>0.939866</td>\n",
       "      <td>0.009622</td>\n",
       "      <td>7</td>\n",
       "      <td>0.954343</td>\n",
       "      <td>0.953229</td>\n",
       "      <td>0.952116</td>\n",
       "      <td>0.953229</td>\n",
       "      <td>0.000909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.787042</td>\n",
       "      <td>0.147065</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.01, 'penalty': 'l1'}</td>\n",
       "      <td>0.543430</td>\n",
       "      <td>0.563474</td>\n",
       "      <td>0.514477</td>\n",
       "      <td>0.540460</td>\n",
       "      <td>0.020113</td>\n",
       "      <td>8</td>\n",
       "      <td>0.550111</td>\n",
       "      <td>0.536748</td>\n",
       "      <td>0.532294</td>\n",
       "      <td>0.539718</td>\n",
       "      <td>0.007571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.719339</td>\n",
       "      <td>0.118678</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2'}</td>\n",
       "      <td>0.977728</td>\n",
       "      <td>0.953229</td>\n",
       "      <td>0.962138</td>\n",
       "      <td>0.964365</td>\n",
       "      <td>0.010125</td>\n",
       "      <td>4</td>\n",
       "      <td>0.986637</td>\n",
       "      <td>0.989978</td>\n",
       "      <td>0.987751</td>\n",
       "      <td>0.988122</td>\n",
       "      <td>0.001389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.759751</td>\n",
       "      <td>0.533439</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l1'}</td>\n",
       "      <td>0.953229</td>\n",
       "      <td>0.935412</td>\n",
       "      <td>0.942094</td>\n",
       "      <td>0.943578</td>\n",
       "      <td>0.007349</td>\n",
       "      <td>6</td>\n",
       "      <td>0.951002</td>\n",
       "      <td>0.961024</td>\n",
       "      <td>0.957684</td>\n",
       "      <td>0.956570</td>\n",
       "      <td>0.004167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.467166</td>\n",
       "      <td>0.278562</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 1, 'penalty': 'l2'}</td>\n",
       "      <td>0.977728</td>\n",
       "      <td>0.957684</td>\n",
       "      <td>0.962138</td>\n",
       "      <td>0.965850</td>\n",
       "      <td>0.008594</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.079755</td>\n",
       "      <td>0.504087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 1, 'penalty': 'l1'}</td>\n",
       "      <td>0.977728</td>\n",
       "      <td>0.959911</td>\n",
       "      <td>0.953229</td>\n",
       "      <td>0.963623</td>\n",
       "      <td>0.010340</td>\n",
       "      <td>5</td>\n",
       "      <td>0.998886</td>\n",
       "      <td>0.998886</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999258</td>\n",
       "      <td>0.000525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.035519</td>\n",
       "      <td>0.307269</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 10, 'penalty': 'l2'}</td>\n",
       "      <td>0.975501</td>\n",
       "      <td>0.966592</td>\n",
       "      <td>0.955457</td>\n",
       "      <td>0.965850</td>\n",
       "      <td>0.008200</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.355393</td>\n",
       "      <td>0.210659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 10, 'penalty': 'l1'}</td>\n",
       "      <td>0.979955</td>\n",
       "      <td>0.966592</td>\n",
       "      <td>0.951002</td>\n",
       "      <td>0.965850</td>\n",
       "      <td>0.011832</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       0.514647      0.031017         0.000000        0.000000    0.01   \n",
       "1       0.787042      0.147065         0.000333        0.000472    0.01   \n",
       "2       1.719339      0.118678         0.000667        0.000472     0.1   \n",
       "3       4.759751      0.533439         0.000625        0.000445     0.1   \n",
       "4       3.467166      0.278562         0.000334        0.000472       1   \n",
       "5      10.079755      0.504087         0.000000        0.000000       1   \n",
       "6       6.035519      0.307269         0.000667        0.000472      10   \n",
       "7      10.355393      0.210659         0.000000        0.000000      10   \n",
       "\n",
       "  param_penalty                        params  split0_test_score  \\\n",
       "0            l2  {'C': 0.01, 'penalty': 'l2'}           0.953229   \n",
       "1            l1  {'C': 0.01, 'penalty': 'l1'}           0.543430   \n",
       "2            l2   {'C': 0.1, 'penalty': 'l2'}           0.977728   \n",
       "3            l1   {'C': 0.1, 'penalty': 'l1'}           0.953229   \n",
       "4            l2     {'C': 1, 'penalty': 'l2'}           0.977728   \n",
       "5            l1     {'C': 1, 'penalty': 'l1'}           0.977728   \n",
       "6            l2    {'C': 10, 'penalty': 'l2'}           0.975501   \n",
       "7            l1    {'C': 10, 'penalty': 'l1'}           0.979955   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.930958           0.935412         0.939866        0.009622   \n",
       "1           0.563474           0.514477         0.540460        0.020113   \n",
       "2           0.953229           0.962138         0.964365        0.010125   \n",
       "3           0.935412           0.942094         0.943578        0.007349   \n",
       "4           0.957684           0.962138         0.965850        0.008594   \n",
       "5           0.959911           0.953229         0.963623        0.010340   \n",
       "6           0.966592           0.955457         0.965850        0.008200   \n",
       "7           0.966592           0.951002         0.965850        0.011832   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                7            0.954343            0.953229   \n",
       "1                8            0.550111            0.536748   \n",
       "2                4            0.986637            0.989978   \n",
       "3                6            0.951002            0.961024   \n",
       "4                1            1.000000            1.000000   \n",
       "5                5            0.998886            0.998886   \n",
       "6                1            1.000000            1.000000   \n",
       "7                1            1.000000            1.000000   \n",
       "\n",
       "   split2_train_score  mean_train_score  std_train_score  \n",
       "0            0.952116          0.953229         0.000909  \n",
       "1            0.532294          0.539718         0.007571  \n",
       "2            0.987751          0.988122         0.001389  \n",
       "3            0.957684          0.956570         0.004167  \n",
       "4            1.000000          1.000000         0.000000  \n",
       "5            1.000000          0.999258         0.000525  \n",
       "6            1.000000          1.000000         0.000000  \n",
       "7            1.000000          1.000000         0.000000  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grid = pd.DataFrame(grid.cv_results_)\n",
    "df_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 流水线操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scikit-learn`引入了`Pipeline`对象。它依次连接多个转换器和分类器（或回归器）。我们可以创建一个如下管道："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "X = X_train\n",
    "y = y_train\n",
    "pipe = make_pipeline(\n",
    "    MinMaxScaler(),\n",
    "    LogisticRegression(\n",
    "        solver='saga', multi_class='auto', random_state=42, max_iter=5000))\n",
    "param_grid = {\n",
    "    'logisticregression__C': [0.1, 1.0, 10],\n",
    "    'logisticregression__penalty': ['l2', 'l1']\n",
    "}\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=3, n_jobs=-1)\n",
    "scores = pd.DataFrame(\n",
    "    cross_validate(grid, X, y, cv=3, n_jobs=-1, return_train_score=True))\n",
    "scores[['train_score', 'test_score']].boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the Pipeline is 0.96\n"
     ]
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train)\n",
    "accuracy = pipe.score(X_test, y_test)\n",
    "print('Accuracy score of the {} is {:.2f}'.format(pipe.__class__.__name__, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以使用`get_params()`检查管道的所有参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('minmaxscaler', MinMaxScaler()),\n",
       "  ('logisticregression',\n",
       "   LogisticRegression(max_iter=5000, random_state=42, solver='saga'))],\n",
       " 'verbose': False,\n",
       " 'minmaxscaler': MinMaxScaler(),\n",
       " 'logisticregression': LogisticRegression(max_iter=5000, random_state=42, solver='saga'),\n",
       " 'minmaxscaler__clip': False,\n",
       " 'minmaxscaler__copy': True,\n",
       " 'minmaxscaler__feature_range': (0, 1),\n",
       " 'logisticregression__C': 1.0,\n",
       " 'logisticregression__class_weight': None,\n",
       " 'logisticregression__dual': False,\n",
       " 'logisticregression__fit_intercept': True,\n",
       " 'logisticregression__intercept_scaling': 1,\n",
       " 'logisticregression__l1_ratio': None,\n",
       " 'logisticregression__max_iter': 5000,\n",
       " 'logisticregression__multi_class': 'auto',\n",
       " 'logisticregression__n_jobs': None,\n",
       " 'logisticregression__penalty': 'l2',\n",
       " 'logisticregression__random_state': 42,\n",
       " 'logisticregression__solver': 'saga',\n",
       " 'logisticregression__tol': 0.0001,\n",
       " 'logisticregression__verbose': 0,\n",
       " 'logisticregression__warm_start': False}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此外，可以将网格搜索称为任何其他分类器以进行预测。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 练习 异构数据：当您使用数字以外的数据时"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St Louis, MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived                                             name     sex  \\\n",
       "0       1         1                    Allen, Miss. Elisabeth Walton  female   \n",
       "1       1         1                   Allison, Master. Hudson Trevor    male   \n",
       "2       1         0                     Allison, Miss. Helen Loraine  female   \n",
       "3       1         0             Allison, Mr. Hudson Joshua Creighton    male   \n",
       "4       1         0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female   \n",
       "\n",
       "       age  sibsp  parch  ticket      fare    cabin embarked boat   body  \\\n",
       "0  29.0000      0      0   24160  211.3375       B5        S    2    NaN   \n",
       "1   0.9167      1      2  113781  151.5500  C22 C26        S   11    NaN   \n",
       "2   2.0000      1      2  113781  151.5500  C22 C26        S  NaN    NaN   \n",
       "3  30.0000      1      2  113781  151.5500  C22 C26        S  NaN  135.0   \n",
       "4  25.0000      1      2  113781  151.5500  C22 C26        S  NaN    NaN   \n",
       "\n",
       "                         home.dest  \n",
       "0                     St Louis, MO  \n",
       "1  Montreal, PQ / Chesterville, ON  \n",
       "2  Montreal, PQ / Chesterville, ON  \n",
       "3  Montreal, PQ / Chesterville, ON  \n",
       "4  Montreal, PQ / Chesterville, ON  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "data = pd.read_csv('data/titanic_openml.csv', na_values='?')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "泰坦尼克号数据集包含分类，文本和数字特征。 我们将使用此数据集来预测乘客是否在泰坦尼克号中幸存下来。\n",
    "\n",
    "让我们将数据拆分为训练和测试集，并将幸存列用作目标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['survived']\n",
    "X = data.drop(columns='survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，可以尝试使用`LogisticRegression`分类器，看看它的表现有多好。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Rekic, Mr. Tido'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22252/1074327380.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#这里肯定会报错。\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\miniconda\\envs\\DL\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1512\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1513\u001b[0m             \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"C\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1514\u001b[1;33m             \u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msolver\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"liblinear\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"sag\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"saga\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1515\u001b[0m         )\n\u001b[0;32m   1516\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda\\envs\\DL\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    574\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 576\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    577\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda\\envs\\DL\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    966\u001b[0m         \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m         \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 968\u001b[1;33m         \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    969\u001b[0m     )\n\u001b[0;32m    970\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda\\envs\\DL\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    736\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    737\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 738\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    739\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    740\u001b[0m                 raise ValueError(\n",
      "\u001b[1;32mD:\\miniconda\\envs\\DL\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1992\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mNpDtype\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1993\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1994\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1995\u001b[0m     def __array_wrap__(\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Rekic, Mr. Tido'"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)#这里肯定会报错。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "大多数分类器都设计用于处理数值数据。 因此，我们需要将分类数据转换为数字特征。 最简单的方法是使用`OneHotEncoder`对每个分类特征进行读热编码。 让我们以`sex`与`embarked`列为例。 请注意，我们还会遇到一些缺失的数据。 我们将使用`SimpleImputer`用常量值替换缺失值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 1., 0.],\n",
       "       [0., 1., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = make_pipeline(SimpleImputer(strategy='constant'), OneHotEncoder())\n",
    "X_encoded = ohe.fit_transform(X_train[['sex', 'embarked']])\n",
    "X_encoded.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这样，可以对分类特征进行编码。 但是，我们也希望标准化数字特征。 因此，我们需要将原始数据分成2个子组并应用不同的预处理：（i）分类数据的独热编；（ii）数值数据的标准缩放(归一化)。 我们还需要处理两种情况下的缺失值： 对于分类列，我们将字符串'`missing_values`'替换为缺失值，该字符串将自行解释为类别。 对于数值数据，我们将用感兴趣的特征的平均值替换缺失的数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_cat = ['sex', 'embarked']\n",
    "col_num = ['age', 'sibsp', 'parch', 'fare']\n",
    "\n",
    "X_train_cat = X_train[col_cat]\n",
    "X_train_num = X_train[col_num]\n",
    "X_test_cat = X_test[col_cat]\n",
    "X_test_num = X_test[col_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler_cat = make_pipeline(SimpleImputer(strategy='constant'), OneHotEncoder())\n",
    "X_train_cat_enc = scaler_cat.fit_transform(X_train_cat)\n",
    "X_test_cat_enc = scaler_cat.transform(X_test_cat)\n",
    "\n",
    "scaler_num = make_pipeline(SimpleImputer(strategy='mean'), StandardScaler())\n",
    "X_train_num_scaled = scaler_num.fit_transform(X_train_num)\n",
    "X_test_num_scaled = scaler_num.transform(X_test_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "#转为稀疏矩阵\n",
    "\n",
    "X_train_scaled = sparse.hstack((X_train_cat_enc,\n",
    "                                sparse.csr_matrix(X_train_num_scaled)))\n",
    "X_test_scaled = sparse.hstack((X_test_cat_enc,\n",
    "                               sparse.csr_matrix(X_test_num_scaled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "csr_matrix用法\n",
    "将数组转化为矩阵，通过行列索引进行转换，输出为行列索引与对应的值<br>\n",
    "具体还有其他用法https://blog.csdn.net/weixin_43486780/article/details/104611813"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1\n",
      "  (0, 2)\t3\n",
      "  (1, 1)\t5\n",
      "  (1, 2)\t6\n",
      "  (2, 0)\t7\n"
     ]
    }
   ],
   "source": [
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "d_A = np.array([[1, 0, 3],\n",
    "                [0, 5, 6],\n",
    "                [7, 0, 0]])\n",
    "s_A = sp.csr_matrix(d_A)\n",
    "print(s_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "转换完成后，我们现在可以组合所有数值的信息。最后，我们使用`LogisticRegression`分类器作为模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the LogisticRegression is 0.7866\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(solver='lbfgs')\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "accuracy = clf.score(X_test_scaled, y_test)\n",
    "print('Accuracy score of the {} is {:.4f}'.format(clf.__class__.__name__, accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
